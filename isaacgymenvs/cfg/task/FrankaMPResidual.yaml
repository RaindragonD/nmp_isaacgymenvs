# used to create the object
name: FrankaMPRRL

physics_engine: ${..physics_engine}

# if given, will override the device setting in gym. 
env:
  numEnvs: ${resolve_default:1024,${...num_envs}}
  envSpacing: 1.5
  episodeLength: 1000
  enableDebugVis: False

  clipObservations: 5.0
  clipActions: 1.0

  frankaDofNoise: 0.2

  aggregateMode: 3

  actionScale: 0.01

  controlType: joint_position  # options are {joint_position, osc}
  controlFrequencyInv: 1

  asset:
    assetRoot: "../../assets"
    assetFileNameFranka: "urdf/franka_description/robots/franka_panda_gripper.urdf"

  # set to True if you use camera sensors in the environment
  enableCameraSensors: False
  image_height: 224
  image_width: 224
  disable_eef: True

  # camera properties
  camera:
    width: 640
    height: 480

  # 14: for Dagger (7 joint angles + 7 goal angles)
  # 1031: for RL with switch, 1024 pcd_feats + 7 joint angles
  # 1038: for residual RL match the output dim of pointnet encoder, note this only works with robomimic ckpts (1024 pcd_feats + 7 joint angles + 7 base_policy_delta)
  # 1045: for residual RL (1024 pcd_feats + 7 joint angles + 7 goal angles + 7 base policy delta)
  numObservations: 1038
  numStates: 1045 # 1038 + pos(3) + vel(3) + sdf
  numActions: 8

  base_policy_url: "jimyoung6709/DRP_Dagger"
  base_policy_sub_steps: 1 # set to ~5 if using fabric
  base_policy_only: False
  no_base_action: False
  hdf5_path: null # hdf5 file that contains env and trajectory info
  batch_idx: 0 # index of the batch of envs to load from the hdf5 file
  use_mean_actions: True

  reaching_reset_threshold: 50
  step_back_on_collision: 0
  reset_on_collision: False

  vis_goal: False

  # video logging
  capture_video: False
  capture_envs: 1
  capture_iter_max: 1
  capture_freq: 5

  is_rrl: True # if training with residual rl or just rl

sim:
  dt: 0.01667 # 1/60
  substeps: 1
  up_axis: "z"
  use_gpu_pipeline: ${eq:${...pipeline},"gpu"}
  gravity: [0.0, 0.0, -9.81]
  physx:
    num_threads: ${....num_threads}
    solver_type: ${....solver_type}
    use_gpu: ${contains:"cuda",${....sim_device}} # set to False to run on CPU
    num_position_iterations: 8
    num_velocity_iterations: 1
    contact_offset: 0.005
    rest_offset: 0.0
    bounce_threshold_velocity: 0.2
    max_depenetration_velocity: 1000.0
    default_buffer_size_multiplier: 5.0
    max_gpu_contact_pairs: 1048576 # 1024*1024
    num_subscenes: ${....num_subscenes}
    contact_collection: 1 # 0: CC_NEVER (don't collect contact info), 1: CC_LAST_SUBSTEP (collect only contacts on last substep), 2: CC_ALL_SUBSTEPS (broken - do not use!)

task:
  randomize: False

pcd_spec:
  num_robot_points: 2048
  num_obstacle_points: 4096
  num_moving_obstacle_points_per_obj: 700
  num_extra_points_per_obj: 500
  num_ground_plane_points: 500
  num_target_points: 2048
  max_rollout_length: 150
  debug: False

dyn_obj:
  type: ["cuboid"] # ["cuboid", "sphere", "mesh"]
  dim_range: [[0.05, 0.05, 0.05], [0.2, 0.2, 0.2]]
  dist_range: [0.1, 0.4]
  vel_range: [0.1, 0.2]
  num_obj: 1
  xyz_threshold: [[-0.3, 0.2], [-0.2, 0.2], [-0.1, 0.6]] # a safety region to prevent the dynamic object from colliding with the robot base
  bounce_back:
    enable: True
    thres: [0.15, 0.3]
  curri_chasing: # curriculum chasing mode will be activated if bounce back is disabled
    update_freq: 20000 # update the chasing steps every certain sim steps
    chasing_steps: [10, 100, 200, 300, 400, 500] # number of sim steps the obstacle chase the robot
    center: [0.5, 0.0, 0.0] # center of the operation space
    radius: 1.5 # stop the obstacle when its moving too far away from the center
